{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy import sparse\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string, time, random\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_fname = 'Data/goblet_book.txt'\n",
    "book_data = open(book_fname, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107542\n"
     ]
    }
   ],
   "source": [
    "print(len(book_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_chars = ''.join(sorted({l for word in book_data for l in word}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "\t\n",
      " !\"'(),-./01234679:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_abcdefghijklmnopqrstuvwxyz}ü•\n"
     ]
    }
   ],
   "source": [
    "print(len(book_chars))\n",
    "print(book_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(book_chars.find('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, \"'\": 5, '(': 6, ')': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '6': 17, '7': 18, '9': 19, ':': 20, ';': 21, '?': 22, 'A': 23, 'B': 24, 'C': 25, 'D': 26, 'E': 27, 'F': 28, 'G': 29, 'H': 30, 'I': 31, 'J': 32, 'K': 33, 'L': 34, 'M': 35, 'N': 36, 'O': 37, 'P': 38, 'Q': 39, 'R': 40, 'S': 41, 'T': 42, 'U': 43, 'V': 44, 'W': 45, 'X': 46, 'Y': 47, 'Z': 48, '^': 49, '_': 50, 'a': 51, 'b': 52, 'c': 53, 'd': 54, 'e': 55, 'f': 56, 'g': 57, 'h': 58, 'i': 59, 'j': 60, 'k': 61, 'l': 62, 'm': 63, 'n': 64, 'o': 65, 'p': 66, 'q': 67, 'r': 68, 's': 69, 't': 70, 'u': 71, 'v': 72, 'w': 73, 'x': 74, 'y': 75, 'z': 76, '}': 77, 'ü': 78, '•': 79}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with each key is a character and value is its position in book_chars (1,80)\n",
    "char2int = dict(zip(book_chars, count(0)))\n",
    "print(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 58, 52]\n"
     ]
    }
   ],
   "source": [
    "# Example of using char2int to encode a string\n",
    "text = 'Nga'\n",
    "indexes = [\n",
    "  letter_mapping[letter] for letter in text \n",
    "  if letter in char2int\n",
    "]\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '\"', 5: \"'\", 6: '(', 7: ')', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '6', 18: '7', 19: '9', 20: ':', 21: ';', 22: '?', 23: 'A', 24: 'B', 25: 'C', 26: 'D', 27: 'E', 28: 'F', 29: 'G', 30: 'H', 31: 'I', 32: 'J', 33: 'K', 34: 'L', 35: 'M', 36: 'N', 37: 'O', 38: 'P', 39: 'Q', 40: 'R', 41: 'S', 42: 'T', 43: 'U', 44: 'V', 45: 'W', 46: 'X', 47: 'Y', 48: 'Z', 49: '^', 50: '_', 51: 'a', 52: 'b', 53: 'c', 54: 'd', 55: 'e', 56: 'f', 57: 'g', 58: 'h', 59: 'i', 60: 'j', 61: 'k', 62: 'l', 63: 'm', 64: 'n', 65: 'o', 66: 'p', 67: 'q', 68: 'r', 69: 's', 70: 't', 71: 'u', 72: 'v', 73: 'w', 74: 'x', 75: 'y', 76: 'z', 77: '}', 78: 'ü', 79: '•'}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with each key is a number in (1,80) and value is corresponding character\n",
    "int2char = {v: k for k, v in char2int.items()}\n",
    "print(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1107542 characters, 80 unique.\n"
     ]
    }
   ],
   "source": [
    "# Another way to read in data\n",
    "data = open(book_fname, 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(chars, vocab_size):\n",
    "    n = len(chars)\n",
    "    x_one_hot = np.zeros((vocab_size,n))    \n",
    "    x_one_hot[[char2int[ch] for ch in chars], range(n)] = 1\n",
    "    return x_one_hot\n",
    "\n",
    "def plotResults(x,y,name='loss',save_name=None):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('n_update')\n",
    "    plt.ylabel(name)\n",
    "    if save_name is not None:\n",
    "        fig.savefig('Figures/'+name+'_'+save_name+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Set hyper-parameters and initialize the RNN’s parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "    \"\"\"\n",
    "    A Vanilla Recurrent neural network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size=80 ,hidden_dim=100, \n",
    "                 weight_scale=0.01, dtype=np.float32,):\n",
    "        \"\"\"\n",
    "        Initialize a new network.\n",
    "\n",
    "        Inputs:\n",
    "        - vocab_size: the total letters of the input\n",
    "        - hidden_dim: Number of units to use in hidden layer\n",
    "        - weight_scale: Scalar giving standard deviation for random initialization\n",
    "          of weights.\n",
    "        - dtype: numpy datatype to use for computation.\n",
    "        \"\"\"\n",
    "        self.h0 = np.zeros((hidden_dim , 1))\n",
    "        \n",
    "        self.params = {}\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.weight_scale = weight_scale\n",
    "                      \n",
    "        self.init_sets()\n",
    "    \n",
    "    \n",
    "    def init_sets(self):\n",
    "        \"\"\"\n",
    "        Initialize model parameters\n",
    "        \"\"\"\n",
    "        # The biases\n",
    "        self.params['b'] = np.zeros((self.hidden_dim,1))  # m x 1\n",
    "        self.params['c'] = np.zeros((self.vocab_size,1))  # K x 1\n",
    "           \n",
    "        # The weights\n",
    "        self.params['U'] = self.weight_scale*np.random.randn(self.hidden_dim,self.vocab_size)  # m x K\n",
    "        self.params['W'] = self.weight_scale*np.random.randn(self.hidden_dim,self.hidden_dim)  # m x m\n",
    "        self.params['V'] = self.weight_scale*np.random.randn(self.vocab_size,self.hidden_dim)  # K x m\n",
    "\n",
    "        for k, v in self.params.items():\n",
    "            self.params[k] = v.astype(self.dtype)\n",
    "        \n",
    "    \n",
    "    ## Exercise 3: Synthesize text from your randomly initialized RNN\n",
    "    def sample(self, x0, n):\n",
    "        \"\"\"\n",
    "        - h0: m x 1 vector of hidden state at time 0 \n",
    "        - x0: K x 1 first input vector\n",
    "        - n: the length of the sequence to generate\n",
    "        \"\"\"\n",
    "        U, W, V = self.params['U'], self.params['W'], self.params['V']\n",
    "        b, c = self.params['b'], self.params['c']\n",
    "        \n",
    "        xnext = np.zeros((len(x0),n))\n",
    "        h, x = self.h0.copy(), x0\n",
    "        for i in range(n):\n",
    "            h = np.tanh(np.dot(W,h) + np.dot(U,x) + b)  # m x 1\n",
    "            s = np.dot(V,h) + c  # K x 1\n",
    "            p = np.exp(s-np.max(s))/np.sum(np.exp(s-np.max(s)))  # K x 1\n",
    "            # find next x\n",
    "            au = np.random.rand()\n",
    "            ix = np.argwhere(np.cumsum(p)>au)[0]\n",
    "            xnext[ix,i] = 1\n",
    "            x = xnext[:,[i]]\n",
    "        \n",
    "        return xnext\n",
    "\n",
    "    def loss(self, X, Y, mode='train'):\n",
    "        \"\"\"\n",
    "        Evaluate loss and gradient for recurrent neural network.\n",
    "        - y=None: for testing\n",
    "        - h0 is mx1 array of initial hidden state\n",
    "        \"\"\"\n",
    "        X = X.astype(self.dtype)\n",
    "        Y = Y.astype(self.dtype)\n",
    "\n",
    "        U, W, V = self.params['U'], self.params['W'], self.params['V']\n",
    "        b, c = self.params['b'], self.params['c']\n",
    "        \n",
    "        _,N = X.shape\n",
    "        \n",
    "        # Forward pass\n",
    "        ht, st, pt = {}, {}, {}\n",
    "        ht[-1] = self.h0.copy()\n",
    "        \n",
    "        loss = 0\n",
    "        for t in range(N):\n",
    "            ht[t] = np.tanh(np.dot(W,ht[t-1]) + np.dot(U,X[:,[t]]) + b)  # m x 1\n",
    "            st[t] = np.dot(V,ht[t]) + c  # K x 1\n",
    "            pt[t] = np.exp(st[t]-np.max(st[t]))/np.sum(np.exp(st[t]-np.max(st[t])))\n",
    "            loss += -np.log(np.dot(Y[:,[t]].T,pt[t]))\n",
    "            \n",
    "        if mode=='test':\n",
    "            return loss\n",
    "        \n",
    "        # Backward pass\n",
    "        grads = {}\n",
    "        dU, dW, dV = np.zeros_like(U), np.zeros_like(W), np.zeros_like(V)\n",
    "        db, dc = np.zeros_like(b), np.zeros_like(c)\n",
    "        dh_next = np.zeros_like(self.h0)\n",
    "        for t in reversed(range(N)):\n",
    "            dst = pt[t] - Y[:,[t]]\n",
    "            dV += np.dot(dst,ht[t].T)\n",
    "            dc = dc + dst\n",
    "            dht = np.dot(V.T,dst) + dh_next\n",
    "            dat = dht*(1-ht[t]*ht[t])  # m x 1\n",
    "            db = db + dat\n",
    "            dU += np.dot(dat,X[:,[t]].T)  # m x K\n",
    "            dW += np.dot(dat,ht[t-1].T)  # m x m\n",
    "            dh_next = np.dot(W.T,dat)\n",
    "               \n",
    "        grads['U'], grads['W'], grads['V'] = dU, dW, dV\n",
    "        grads['b'], grads['c'] = db, dc\n",
    "        \n",
    "        for k,v in grads.items():\n",
    "            np.clip(v,-5,5,out=v)\n",
    "        \n",
    "        self.h0 = ht[N-1].copy()\n",
    "        return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGradients(X,Y,h=1e-4):\n",
    "    eps = 1e-30\n",
    "    err = 1e-6\n",
    "    \n",
    "    net = RNN(hidden_dim=5)\n",
    "    _,grads_a = net.loss(X,Y)\n",
    "    \n",
    "    params = net.params\n",
    "    grads_n = {}    \n",
    "    for key,param in params.items():\n",
    "        grads_n[key] = np.zeros_like(param)\n",
    "        total_error = 0\n",
    "        for i in range(param.size):\n",
    "            param.flat[i] += h\n",
    "            l1 = net.loss(X,Y,mode='test')\n",
    "            param.flat[i] -= 2*h\n",
    "            l2 = net.loss(X,Y,mode='test')\n",
    "            param.flat[i] += h\n",
    "            grads_n[key].flat[i] = (l1-l2)/(2*h)\n",
    "        # Relative error\n",
    "        error = np.abs(grads_a[key]-grads_n[key])/np.maximum(eps,np.abs(grads_a[key])+np.abs(grads_n[key]))\n",
    "        total_error += np.sum(error>err)\n",
    "        max_error = np.max(error)\n",
    "        print('The number of errors (relative error > 1e-6) of {}: {}'.format(key, total_error))\n",
    "        print('The maximum of relative error of {}: {}'.format(key, max_error))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Synthesize text from your randomly initialized RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input\n",
    "x0 = np.zeros((80,1))\n",
    "x0[char2int['N']] = 1\n",
    "h0 = np.zeros((100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNN()\n",
    "xnext = net.sample(x0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 200)\n"
     ]
    }
   ],
   "source": [
    "print(xnext.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68 18 24 50  5 13 13  0 39 63 42  6 38 28 49 68 35 69 58 45 22 31 46 25\n",
      " 20 42  1 18 54 74 16 39 73 29 40  6 21 18  1 19 49 53 74 60 43 56 59 31\n",
      " 14 53 37 43 69 29 42 36 68 79  2  3 16  9 23  0 40 24 44  5 75 27 53 62\n",
      " 32 45 26 74 38 32 22 20  2 53 38  1 71 63  3 46 41 63  9 61 73  8 79 50\n",
      " 27 52 78 57 12  3 49 35 35 15 57 66 41 14 39 37 17 23 25 58 48 55 36 42\n",
      " 56 54  0 54 61 78 66 17 65 67 36 34 27  7 22 43 32 53 23 38 24 30  7 58\n",
      " 53 77 10 33 14 36 38 68 17 35 60  9  0 54 27  4 74 51 65 68 38 57 11 24\n",
      " 31  9 66  5 51 74 15 37 71 49 46 45 23 53 76 33 13 64 54 52 17 61 23 52\n",
      " 52 72 74 10 49  1 11 43]\n",
      "r7B_'11\tQmT(PF^rMshW?IXC:T\n",
      "7dx4QwGR(;7\n",
      "9^cxjUfiI2cOUsGTNr• !4-A\tRBV'yEclJWDxPJ?: cP\n",
      "um!XSm-kw,•_Ebüg0!^MM3gpS2QO6AChZeNTfd\tdküp6oqNLE)?UJcAPBH)hc}.K2NPr6Mj-\tdE\"xaorPg/BI-p'ax3Ou^XWAczK1ndb6kAbbvx.^\n",
      "/U\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(xnext, axis=0))\n",
    "text = ''.join(int2char[ix] for ix in np.argmax(xnext, axis=0))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Implement the forward & backward pass of back-prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chars = book_data[:25]\n",
    "Y_chars = book_data[1:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARRY POTTER AND THE GOBL\n",
      "ARRY POTTER AND THE GOBLE\n"
     ]
    }
   ],
   "source": [
    "print(X_chars)\n",
    "print(Y_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = one_hot_matrix(X_chars)\n",
    "Y = one_hot_matrix(Y_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 25) (80, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of errors (relative error > 1e-6) of b: 0\n",
      "The maximum of relative error of b: 2.1481670643567495e-08\n",
      "The number of errors (relative error > 1e-6) of c: 0\n",
      "The maximum of relative error of c: 2.8953546415392706e-08\n",
      "The number of errors (relative error > 1e-6) of U: 0\n",
      "The maximum of relative error of U: 8.838543408273836e-07\n",
      "The number of errors (relative error > 1e-6) of W: 7\n",
      "The maximum of relative error of W: 2.490667611709796e-05\n",
      "The number of errors (relative error > 1e-6) of V: 15\n",
      "The maximum of relative error of V: 1.710842866486928e-06\n"
     ]
    }
   ],
   "source": [
    "h0 = np.zeros((5,1))\n",
    "checkGradients(X,Y,h0,h=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Train RNN using AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, model, data, **kwargs):\n",
    "        \n",
    "        self.model = model\n",
    "        self.data = data\n",
    "\n",
    "        # Unpack keyword arguments\n",
    "        self.optimizer = kwargs.pop('optimizer', 'adagrad')\n",
    "        self.optim_config = kwargs.pop('optim_config', {})\n",
    "        self.seq_length = kwargs.pop('seq_length', 25)\n",
    "        self.num_epochs = kwargs.pop('num_epochs', 10)\n",
    "\n",
    "        self.print_every = kwargs.pop('print_every', 100)\n",
    "        self.verbose = kwargs.pop('verbose', True)\n",
    "\n",
    "        # Throw an error if there are extra keyword arguments\n",
    "        if len(kwargs) > 0:\n",
    "            extra = ', '.join('\"%s\"' % k for k in list(kwargs.keys()))\n",
    "            raise ValueError('Unrecognized arguments %s' % extra)\n",
    "\n",
    "        self._reset()\n",
    "    \n",
    "    \n",
    "    def _reset(self):\n",
    "        \"\"\"\n",
    "        Set up some book-keeping variables for optimization. Don't call this\n",
    "        manually.\n",
    "        \"\"\"\n",
    "        # Set up some variables for book-keeping\n",
    "        self.best_loss = 0\n",
    "        self.best_params = {}\n",
    "        self.loss_history = []\n",
    "        self.smooth_loss_history = []\n",
    "        self.train_acc_history = []\n",
    "        self.val_acc_history = []\n",
    "\n",
    "        # Make a deep copy of the optim_config for each parameter\n",
    "        self.optim_configs = {}\n",
    "        for p in self.model.params:\n",
    "            d = {k: v for k, v in self.optim_config.items()}\n",
    "            self.optim_configs[p] = d\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Run optimization to train the model.\n",
    "        \"\"\"\n",
    "        num_train = len(self.data)\n",
    "        hidden_dim = self.model.hidden_dim\n",
    "        vocab_size = self.model.vocab_size\n",
    "        seq_length = self.seq_length\n",
    "        iterations_per_epoch = max(num_train // seq_length, 1)\n",
    "        num_iterations = self.num_epochs * iterations_per_epoch\n",
    "        \n",
    "        smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "        self.best_loss = smooth_loss\n",
    "        pos = 0\n",
    "        for t in range(num_iterations):          \n",
    "            if pos+seq_length+1>=len(self.data) or t==0:\n",
    "                self.model.h0 = np.zeros((hidden_dim,1)) # reset h0\n",
    "                pos = 0\n",
    "            # preparing data to train\n",
    "            X_chars = self.data[pos:pos+seq_length]\n",
    "            Y_chars = self.data[pos+1:pos+seq_length+1]\n",
    "            X = one_hot_matrix(X_chars, vocab_size)\n",
    "            Y = one_hot_matrix(Y_chars, vocab_size)\n",
    "            # Print sample from the model now and then\n",
    "            if self.verbose and t % self.print_every == 0: \n",
    "                sample_ix = self.model.sample(X[:,[0]], 200)\n",
    "                txt = ''.join(int2char[ix] for ix in np.argmax(sample_ix, axis=0))\n",
    "                print('----\\n %s \\n----' % (txt, ))\n",
    "            \n",
    "            # Compute loss and gradient\n",
    "            loss, grads = self.model.loss(X, Y)\n",
    "            self.loss_history.append(loss)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001 \n",
    "            self.smooth_loss_history.append(smooth_loss)\n",
    "            # Print training smooth_loss and sample from the model now and then\n",
    "            if self.verbose and t % self.print_every == 0: \n",
    "                print('(Iteration %d / %d) loss: %f' % (\n",
    "                       t + 1, num_iterations, smooth_loss))\n",
    "            \n",
    "            # Perform a parameter update\n",
    "            for p, w in self.model.params.items():\n",
    "                dw = grads[p]\n",
    "                config = self.optim_configs[p]\n",
    "                next_w, next_config = globals()[self.optimizer](w, dw, config)\n",
    "                self.model.params[p] = next_w\n",
    "                self.optim_configs[p] = next_config\n",
    "                \n",
    "            pos += seq_length\n",
    "            \n",
    "            # Check train and val accuracy on the first iteration, the last\n",
    "            # iteration, and at the end of each epoch.\n",
    "            epoch_end = (t + 1) % iterations_per_epoch == 0\n",
    "            first_it = (t == 0)\n",
    "            last_it = (t == num_iterations - 1)\n",
    "            if first_it or last_it or epoch_end:\n",
    "                # Keep track of the best model\n",
    "                if smooth_loss < self.best_loss:\n",
    "                    self.best_loss = smooth_loss\n",
    "                    self.best_params = {}\n",
    "                    for k, v in self.model.params.items():\n",
    "                        self.best_params[k] = v.copy()\n",
    "\n",
    "        # At the end of training swap the best params into the model\n",
    "        self.model.params = self.best_params\n",
    "\n",
    "\n",
    "\n",
    "def adagrad(w, dw, config=None):\n",
    "    \"\"\"\n",
    "    Performs a variant of stochastic gradient descent, AdaGrad.\n",
    "\n",
    "    config format:\n",
    "    - learning_rate: Scalar learning rate.\n",
    "    \"\"\"\n",
    "    if config is None: config = {}\n",
    "    config.setdefault('learning_rate', 0.1)\n",
    "    config.setdefault('epsilon', 1e-8)\n",
    "    config.setdefault('m', np.zeros_like(w))\n",
    " \n",
    "    config['m'] += dw**2\n",
    "    next_w = w - config['learning_rate']*dw/(np.sqrt(config['m'])+config['epsilon'])\n",
    "\n",
    "    return next_w, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " x1F4tMNVRA;hQdcf\n",
      "us;2eQev\"?eyq_R^}XurFOH?;OKq 1j1H\n",
      "•XjwW}(msV}vwpBEq•'d4s\"o.0rRMWhzrEH^ W•üTlCahBuXu,,RF,TqO;wN\n",
      "EetOCAiHJP4L0xdPWBaf_J^SR;ic.EC};fPh\"(Rz}^Y4?pq.Vd6L4e'zry\tJXWFP7kZd2SmvjbcpCK/yteZ'Q!X• \n",
      "----\n",
      "(Iteration 1 / 443010) loss: 109.550669\n",
      "----\n",
      " unkeallgem pullerry gore harol it.\n",
      " Ek ofmooniyh. thas at withcee of thhe hus  thly wrraplicht a mis,\"?\"  Amen ofed werim beinge gtard ealle warcret ofly hise carire; he Dugoferk do mames besandny, pi \n",
      "----\n",
      "(Iteration 10001 / 443010) loss: 52.856775\n",
      "----\n",
      " egt, a conke S heon, in the gone himain it us the ters fored at ham, burht urnthouse?\"  er. Caiced achr.  Thearing awing.  Harry a and thead hingep let-werdwing it Ha rooms thick upporent anf, youp wh \n",
      "----\n",
      "(Iteration 20001 / 443010) loss: 49.432265\n",
      "----\n",
      " ese. . . perbious to com sayed orming a axtore hom pidly anne ewends expice of Hermies - rowor had agor ach as flilce thar on,\" roses. . . . . . Wowen steaked, plopberdre all to lote con list caure eS \n",
      "----\n",
      "(Iteration 30001 / 443010) loss: 48.232226\n",
      "----\n",
      " rough elir blofle trounghir; down waststorep, heared racking the frithald the rooked and but, was ow, agove ratwelr thed. Vevingung becend been the nouverdest his wand, the gileded Beinented. . . -\"\n",
      "K \n",
      "----\n",
      "(Iteration 40001 / 443010) loss: 46.902468\n",
      "----\n",
      "  mealirs briclunse so here de, and looked that exartede's sovantation?  pouth where haved hat net, and comios, 'soad on!\"\n",
      "\"Ye albuing and Deestely,\" she thes are to mentth'r yes of forand regcher of t \n",
      "----\n",
      "(Iteration 50001 / 443010) loss: 47.932958\n",
      "----\n",
      " pned ho deming in ithors ding notep-ing rofl wiserte,\" stowl ingwaned and hair fors, what.\n",
      "\"Then't Harry. Wanting.\n",
      "\"Hermicaly.  \"Yougen butching As. I?  And tere, where his soudso.  Nene face, an con, \n",
      "----\n",
      "(Iteration 60001 / 443010) loss: 46.441848\n",
      "----\n",
      " wcalk sood gain Ron bawte had by they whims and fonery.  \"Helly thas of the got earrer.  The ay seeds, he Porked yind. Hermione his stycind.  evind wes agrithass weting to you dingiclas Harry begher,  \n",
      "----\n",
      "(Iteration 70001 / 443010) loss: 46.166608\n",
      "----\n",
      " y had Dumwing tarkingwtnainiun hin indore, illy mutcer said! boo mumped at Whasal trims abvee look bewayshar yint arougw and hearn for to the lestrysingrayen.  \"\"There the save bothy mowely, thet unde \n",
      "----\n",
      "(Iteration 80001 / 443010) loss: 44.358209\n",
      "----\n",
      " nd Hary or,\" said a lote por muvhering ontir askuly Crece Vookuse hisist, dold a wicchmis arous, Flissed to said, ent to pight dad were of abore on then lew him of him as woull.  The rofning beser wiz \n",
      "----\n",
      "(Iteration 90001 / 443010) loss: 45.154974\n",
      "----\n",
      "  lingonc And the Ron I mumpliling, welll gat agould I wasked flal nome you, it on it sprented-in ancined thoulgent his at of I we wizersten this mest corsing a said Harry vouttonre,\" down, and at \"I s \n",
      "----\n",
      "(Iteration 100001 / 443010) loss: 46.086686\n",
      "----\n",
      " n from the toicking, wash the ouh, he her thehed gast about to you tring how - in the drekenden tobosherly to the alds, and hum say Ce. he car Chand two.\n",
      "There aworet ereless...\n",
      " He rookle come noof,  \n",
      "----\n",
      "(Iteration 110001 / 443010) loss: 44.264144\n",
      "----\n",
      " e walf yin allnes, budn't come alin, \"He quat to Chowg in, wely an clsereder fanoald From comespering he aflled at juat in sureply, butsear-finge was efoundss ant. \"ANloy, whomemed the rywimpin onsema \n",
      "----\n",
      "(Iteration 120001 / 443010) loss: 44.556745\n",
      "----\n",
      " eadly eyen you lloudd and squin as he low, was to might.\n",
      "Nob it with the sigher every a tan could Ml. Crouch wind clould in it vet'er?\"\n",
      "He vorve.  You!\"\n",
      "\"Non then tey mors.\"\n",
      "\"You, mols!\"  ceat of Dhat \n",
      "----\n",
      "(Iteration 130001 / 443010) loss: 43.338778\n",
      "----\n",
      " e Indomocied though he nit on I the sald whith and Mlyisheranl.\n",
      "\"I'ls teing and snreace the grinking of as their leged and hatains is on with they and manber what neted they were simeniag fed - meven  \n",
      "----\n",
      "(Iteration 140001 / 443010) loss: 46.591395\n",
      "----\n",
      " ing to sour anate doon uneter.\n",
      "\n",
      "\"How're amore as, \"I hare but call of looking reare.  \"Bow Hodrofting,\" sarry.  flinn beglaxite.  Bairy?  \"I had not thatches.\n",
      "\"Whe back, inced it have atte just to ceo \n",
      "----\n",
      "(Iteration 150001 / 443010) loss: 43.758281\n",
      "----\n",
      " sall to Henry morname Hwroul!\" h'rnober feople.  So Jurge quitime Beg,\" she ?\" Whone looky was leek Greathale indo thook he?\"\n",
      "Hanriet it dalked, froget hen' arn and if coortre. \"What?\" Darre, the him  \n",
      "----\n",
      "(Iteration 160001 / 443010) loss: 44.169775\n",
      "----\n",
      " thew the Leggwing tung, \"ento to Mader leen was out at exaidonl, apard,\" sauffwere off?\"\n",
      "He corresert Tow the stand to the want there.  Plidgasblaided,\" Hermiel - Darn's of the two had glalces, strest \n",
      "----\n",
      "(Iteration 170001 / 443010) loss: 43.133690\n",
      "----\n",
      " urese by toblen geht, and Vedis which pot Dude; AS loud, . \"Arsaire an Aglind Voldemort yousthing.  Moody, westock Meds.  Whain ender, stimpering that't in ever?\n",
      "Harry felttly, tha wall whour colltsio \n",
      "----\n",
      "(Iteration 180001 / 443010) loss: 44.157511\n",
      "----\n",
      " . . You'rly with theppele said My. Dudped didn a oven of prefoin\n",
      "\"Ermonaid peudainly filfougnticus.\"\n",
      "\"So the mat's you's thoughace over and ligen so Harry you painofused to he hey smucul wrops anjugni \n",
      "----\n",
      "(Iteration 190001 / 443010) loss: 44.447788\n",
      "----\n",
      "  dook pist.\"\n",
      "Conficals goting into thin'y were in-neire was?\"\n",
      "He him.\"\n",
      "\"A telte breins's squilt and styeted jome of they wouch, ame to wordented of Hagrad, but arovedry, shar out now Fthing wound owe' \n",
      "----\n",
      "(Iteration 200001 / 443010) loss: 43.182363\n",
      "----\n",
      " are tharo-dear, Rons the riffin't Renarcered toble I been of not are Harery?\"\" Shating at they lange've hey, hers thy mast aloa he hime daybeds fort, the cable you, bus the hadkior, and the protely.   \n",
      "----\n",
      "(Iteration 210001 / 443010) loss: 43.188153\n",
      "----\n",
      " cklabal on thes as have bote dagtive away my the beeps barts, tee a room.  Hhrreever, mut wizard busong tell.  Whrekens . . .\"\n",
      "\"Oh a did dease eyes fredombley is back odent at Harry to meed to he outo \n",
      "----\n",
      "(Iteration 220001 / 443010) loss: 41.988681\n",
      "----\n",
      " jerou-ning thoked sin'very -\" cewnon, a thar were with the Harry's to Ont Croomatthed, grow.\"\n",
      "\"Pyoited nors.  Fllowly not ever you harought you faoo. \"Ar on the mughty lincc, splanamany the iverber've \n",
      "----\n",
      "(Iteration 230001 / 443010) loss: 42.639044\n",
      "----\n",
      " re at his handud as grubre.  Andery ackmeing betall the waardertixilong cast would of they the touldn' \"Professabley, ruck of the bent, yours. . . the staped erpieterater tardowerer ustind - Sumbledro \n",
      "----\n",
      "(Iteration 240001 / 443010) loss: 43.213628\n",
      "----\n",
      " ouised - had not the emple lucking Manisaldent ?\" Inte, stind he sutrapill romiching Snape!\" who looking it tind.\n",
      "\"Row, he about you bade grish of yourthing to mats at cast said dent around.\n",
      "It on. .. \n",
      "----\n",
      "(Iteration 250001 / 443010) loss: 43.923834\n",
      "----\n",
      " about he?  Thoughtahed crusking by was Lorried the oppritely fllapion aily did to about Harry's as\"  ghangly frees, out liope incwremel Werms on thong it how.  Nom, broulled ride cong ut  The Dinking  \n",
      "----\n",
      "(Iteration 260001 / 443010) loss: 41.900600\n",
      "----\n",
      " s all tlouds was sacting gizas.\n",
      "\"Whace - was puden the stytcelvel? that the supirt, ain ees.  He hen wimned to she noom and Verters,\" hae pasting, as beheardpeanon of the Hoom to the it?\" \"Wemtory.\n",
      "Ka \n",
      "----\n",
      "(Iteration 270001 / 443010) loss: 43.241892\n",
      "----\n",
      " !\"\n",
      "Thit watte, his fering acame theres zowadney out dis ortond intaid teely disher, in and Cop anysedy of to joup caulding.\" saivy?\"\n",
      "\"What satutuon a wan for Peted Wifffiss good himed she Mading Rong, \n",
      "----\n",
      "(Iteration 280001 / 443010) loss: 43.754374\n",
      "----\n",
      "  his peanece?\n",
      "In hol sar sime about were pallfutce moor me fore?  The had fact.\n",
      "Beinding, just by Brobse face, Harry s- he to dever she clidgiggniol ut of the saived ant's a didn't hims,\" sneazloy wer \n",
      "----\n",
      "(Iteration 290001 / 443010) loss: 42.410409\n",
      "----\n",
      " and he Donath and Coggand reboaked sundening to enters mo, re fach had it letst of blats,\" said Hoghar hand on had know Eonder to done fomening going - he rying.\n",
      "\"I'm crobb, angist betaid of thel.\"\n",
      "\"H \n",
      "----\n",
      "(Iteration 300001 / 443010) loss: 41.126622\n",
      "----\n",
      " aven' fut to hearf'm by nother?\"  said Gely it.  Then sodd Owo rugg him dixidal where her!\"\n",
      "\"Harry.  \"Iim as Tome of to the was Dor, 'voug, any and beght that Eather, he, about trowat!\"\n",
      "\"What.\n",
      "\"The st \n",
      "----\n",
      "(Iteration 310001 / 443010) loss: 41.238966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " ed, dray thim knastome the to jooch Cedsimisins.  Fher?\"\n",
      "\"Chaired of the could at by the pleicke theres, doorely, whark been and crosppedning to that it.  she and sheat the your een should Snakeyen. H \n",
      "----\n",
      "(Iteration 320001 / 443010) loss: 42.402553\n",
      "----\n",
      " ic a the stantely, as by ressicinged, plawed to Hagik to, spah his welting to wink, the door down furies and you'le wain.  Stours.  Dum!\" said Rou novery.\n",
      "\"Loomponce fore them - Olly rowe.  \"I lealg a \n",
      "----\n",
      "(Iteration 330001 / 443010) loss: 42.323424\n",
      "----\n",
      " ffpistngering ountries.\n",
      "The enton?\"\n",
      "\"\n",
      "HHowShover to the Henther lookiny.  We its,\" said at Werent,\" said Hermeeportly.\n",
      "\"Where smomblewoldome sik was but a mastch and the strets was hap en something at \n",
      "----\n",
      "(Iteration 340001 / 443010) loss: 42.766548\n",
      "----\n",
      " ken the Jorkended's her ho rose, Vag thire you andwice wroag Take sard Cumpill.  As it all could was cark, Harry shand simery, - and was then in the sharter rafirainst the offer with a banted and What \n",
      "----\n",
      "(Iteration 350001 / 443010) loss: 42.278348\n",
      "----\n",
      " hey no verytly.\n",
      "Geon!\" Wery'rred Abo dizater around.  He he sullenod of moin,\" leay byenbing in sharthing, they kediff as murely palpsofion bref and throple go, slifgenter.\n",
      "\"You of excent welungiond,  \n",
      "----\n",
      "(Iteration 360001 / 443010) loss: 43.671559\n",
      "----\n",
      " oun thak you have get toon planfers could parting epat some-ntaiced champiod, jush, himseloow an, whohe afforg - Hogwing, and roll was want to the stipped?\"\n",
      "\"From Pang prips in his latounding tome hel \n",
      "----\n",
      "(Iteration 370001 / 443010) loss: 42.066621\n",
      "----\n",
      " reaties, aletel.  Wet tro wropsts ame Not and come on all one more onured day's not behind to find the Hagrid we durnering the bean it.  Ockly wan were frost's the sostaction.  \"We sarts keacuriated l \n",
      "----\n",
      "(Iteration 380001 / 443010) loss: 42.483442\n",
      "----\n",
      " h to ever didagom canrts faciell armowed fow. . . . . .  Ive not looking leep the clote and home, fakiced sivissock ait not trapicalped in like themef you ruth, though gridgdiffins,\" said Harry out.   \n",
      "----\n",
      "(Iteration 390001 / 443010) loss: 40.961367\n",
      "----\n",
      " es back viek them to the ednersond?\"\n",
      "\t\"It ween undering, as moot of the was worlin and his look rooms her of voigh witch at anpme cering with ment to at he kingging for untine the looking you that ske \n",
      "----\n",
      "(Iteration 400001 / 443010) loss: 42.127922\n",
      "----\n",
      "  Ron, suitiess awnone noun think, andee, the rettayed Krumched it\"\n",
      "\"Owind, rowed firme will down and it's cluscholle the clece.\n",
      "He distrent would geancepids turd malaly hive-ene beade lefl wake great  \n",
      "----\n",
      "(Iteration 410001 / 443010) loss: 43.417084\n",
      "----\n",
      "  af.  Ok awaystand tow to you hels of Fle her stizion, but foo Intle - Harry her back.\n",
      "\"Book did fort.  Fung pold.  \"Trowen the Medm not them coared!\"\n",
      "Wheored, shorol of of with be thrmimare.  Dudge's \n",
      "----\n",
      "(Iteration 420001 / 443010) loss: 41.410558\n",
      "----\n",
      " nd - now Ron for gridnaw take Porlering to glots.  \"Westre moved, anjuride gollespsted into the tear arouc still were have held steair-carlinch.  Os deape bitter? \"Pody - his and Perve day asking Pooc \n",
      "----\n",
      "(Iteration 430001 / 443010) loss: 42.339964\n",
      "----\n",
      "  very of indave a har the of seveaked.\"\n",
      "Harmione thougllide Harry of of there beeried.  Arterytoned.  \"Ed is bast lostems me to it cloged and Eath the used ceth eye\n",
      "Voldealf trean.  Ow and all to from \n",
      "----\n",
      "(Iteration 440001 / 443010) loss: 40.835866\n",
      "Execution time:  3841.2811501026154\n"
     ]
    }
   ],
   "source": [
    "net = RNN()\n",
    "model = Model(net, book_data,\n",
    "              num_epochs=10,\n",
    "              optimizer='adagrad',\n",
    "              optim_config={\n",
    "                  'learning_rate': 0.1},\n",
    "              verbose=True, print_every=10000)\n",
    "\n",
    "tic = time.time()\n",
    "model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_updates = len(book_data)//25*model.num_epochs\n",
    "x = np.arange(0,n_updates,1000)\n",
    "loss = np.squeeze(np.array(model.loss_history))[x]\n",
    "plotResults(x,loss,name='smooth_loss',save_name='10_epochs_1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40.52186834]]\n",
      "ard, slel.  Sigwive the.  Lik very But Dumbledoref, and tormated nold himpeen,\" Harry son't laugher his to to anvicks.  \"He door me houghor, \"Thated them, but he's it orfath at it her sa tow Harry, \"Son.\"  \"Davenghed to in the a been for to Harry,\" he the comporing to reastle eybligh but beserived on the golles not her stormail offied.  \"Thet be would's cleatoms on stlace could tain.\"\n",
      "That was take got wint as the touther trees it and the end had wiel, Harry.  They ever to up aboit usted to his that Dup, wherily stay frowm the denge fet whose had Imbyges.  \"He were know. Dumbledore time ling with,\" said yed up orme've curming to that\n",
      "\"Now.  \"Moviet a girs,\" Iad gooked a whilp had the scraut not and shag sike Harry.  Harry dims told.  \"Soled Boway had the sally serted Dood; aront beandy apill theudgen the rowin info the tothof.  He toun ever tiks in the troulkstatifilct and Geoble that Dumbledore said, and Dumbledorrst.  Exs byemw.\n",
      "\"Dopters.  His drawing hern't fore staate slisen, it, h\n"
     ]
    }
   ],
   "source": [
    "print(model.best_loss)\n",
    "x0 = one_hot_matrix(book_data[0], model.model.vocab_size)\n",
    "\n",
    "xnext = model.model.sample(x0,1000)\n",
    "text = ''.join(int2char[ix] for ix in np.argmax(xnext, axis=0))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
